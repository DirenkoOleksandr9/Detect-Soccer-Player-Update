{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Safety shim for stray JSON cell execution\n",
        "null = None\n",
        "true = True\n",
        "false = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zolPS4FJHmaY"
      },
      "source": [
        "# ⚽ Soccer Player Highlight Reel Generator - Production Grade\n",
        "\n",
        "This notebook implements a complete, production-grade, end-to-end pipeline for generating personalized soccer player highlight reels. This is an advanced version with sophisticated algorithms for each stage.\n",
        "\n",
        "## 🚀 Advanced Features\n",
        "- Player Detection: High-performance YOLOv8 for person detection.\n",
        "- Multi-Object Tracking: Full implementation of ByteTrack with a Kalman Filter for motion prediction and Hungarian Algorithm for association.\n",
        "- Long-term Re-Identification: A hybrid system using a Deep CNN for appearance embeddings combined with color histograms and Jersey OCR.\n",
        "- Intelligent Event Detection: Advanced kinematics-based event detector.\n",
        "- Professional Video Assembly: Integration of PySceneDetect to find natural scene boundaries for clean clip extraction, stitched with FFmpeg.\n",
        "\n",
        "## ⚡ How to Use\n",
        "1. Enable GPU: Runtime → Change runtime type → T4 GPU\n",
        "2. Run All Cells: Runtime → Run all\n",
        "3. Upload Video when prompted\n",
        "4. Wait for processing\n",
        "5. Download results automatically\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtXhGf4eHmab",
        "outputId": "a6011f5e-9922-43fe-f3be-3054a0410a55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing dependencies...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCUDA available: True\n",
            "GPU: Tesla T4\n",
            "Setup complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"Installing dependencies...\")\n",
        "!pip install ultralytics torch torchvision opencv-python-headless easyocr scikit-learn numpy pandas tqdm pillow 'scenedetect[opencv]' --quiet\n",
        "import torch, os\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU detected - using CPU (will be much slower)\")\n",
        "os.makedirs('/content/videos', exist_ok=True)\n",
        "os.makedirs('/content/output', exist_ok=True)\n",
        "os.makedirs('/content/temp_clips', exist_ok=True)\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "3TNx8afjHmac",
        "outputId": "760100f2-a592-4ea8-948c-7d31150e93fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please upload your soccer match video file.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b57e862f-3a80-45aa-b58e-699c26c70e59\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b57e862f-3a80-45aa-b58e-699c26c70e59\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 9.mp4 to 9.mp4\n",
            "Video uploaded: /content/videos/9.mp4\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "print(\"Please upload your soccer match video file.\")\n",
        "uploaded = files.upload()\n",
        "video_path = None\n",
        "for filename in uploaded.keys():\n",
        "    if filename.lower().endswith(('.mp4', '.avi', '.mov')):\n",
        "        destination_path = f'/content/videos/{filename}'\n",
        "        shutil.move(filename, destination_path)\n",
        "        print(f\"Video uploaded: {destination_path}\")\n",
        "        video_path = destination_path\n",
        "        break\n",
        "if not video_path:\n",
        "    print(\"No video file found. Please upload an MP4, AVI, or MOV file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n31YleGHmac",
        "outputId": "bf50e121-2240-4bfd-97f7-4034380358f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Modules imported.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "from ultralytics import YOLO\n",
        "import easyocr\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import subprocess\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import List, Dict, Tuple\n",
        "from scenedetect import open_video, SceneManager\n",
        "from scenedetect.detectors import ContentDetector\n",
        "print(\"Modules imported.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uUEmLeBxHmad"
      },
      "outputs": [],
      "source": [
        "class SoccerPlayerDetector:\n",
        "    def __init__(self, model_name: str = 'yolov8n.pt', conf_thresh: float = 0.35):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.model = YOLO(model_name)\n",
        "        self.model.to(self.device)\n",
        "        self.conf_thresh = conf_thresh\n",
        "    def process_video(self, video_path: str, output_path: str) -> List[Dict]:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            return []\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        all_detections = []\n",
        "        with tqdm(total=total_frames, desc=\"Stage 1: Detecting players\") as pbar:\n",
        "            for frame_idx in range(total_frames):\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                results = self.model(frame, classes=[0], imgsz=960, verbose=False)\n",
        "                detections = []\n",
        "                if len(results) > 0 and results[0].boxes is not None:\n",
        "                    for box in results[0].boxes:\n",
        "                        if box.conf[0] >= self.conf_thresh:\n",
        "                            detections.append({'bbox': [int(coord) for coord in box.xyxy[0].tolist()], 'confidence': float(box.conf[0])})\n",
        "                all_detections.append({\"frame_id\": frame_idx, \"detections\": detections})\n",
        "                pbar.update(1)\n",
        "        cap.release()\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(all_detections, f, indent=2)\n",
        "        return all_detections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Z1Zz-o02Hmad",
        "outputId": "a1d5d426-cfe8-4e99-bfc3-5f2851edc5a3"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2274920068.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2274920068.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Tracking note: linear_assignment fix is built into ByteTrack class below; no hotpatch cell needed.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaRU9AOkHmad"
      },
      "outputs": [],
      "source": [
        "class KalmanFilter:\n",
        "    def __init__(self):\n",
        "        self.kf = cv2.KalmanFilter(7, 4)\n",
        "        self.kf.measurementMatrix = np.array([[1,0,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,1,0,0,0,0], [0,0,0,1,0,0,0]], np.float32)\n",
        "        self.kf.transitionMatrix = np.array([[1,0,0,0,1,0,0], [0,1,0,0,0,1,0], [0,0,1,0,0,0,0], [0,0,0,1,0,0,1], [0,0,0,0,1,0,0], [0,0,0,0,0,1,0], [0,0,0,0,0,0,1]], np.float32)\n",
        "        cv2.setIdentity(self.kf.processNoiseCov, 1e-2)\n",
        "        cv2.setIdentity(self.kf.measurementNoiseCov, 1e-1)\n",
        "        cv2.setIdentity(self.kf.errorCovPost, 1)\n",
        "    def predict(self):\n",
        "        return self.kf.predict()\n",
        "    def update(self, bbox: List[float]):\n",
        "        x, y, w, h = bbox\n",
        "        measurement = np.array([x + w / 2, y + h / 2, w / h, h], dtype=np.float32).reshape(4, 1)\n",
        "        self.kf.correct(measurement)\n",
        "    def init(self, bbox: List[float]):\n",
        "        x, y, w, h = bbox\n",
        "        self.kf.statePost = np.array([x + w / 2, y + h / 2, w / h, h, 0, 0, 0], dtype=np.float32).reshape(7, 1)\n",
        "class STrack:\n",
        "    def __init__(self, tlwh: List[float], score: float):\n",
        "        self.tlwh = np.asarray(tlwh, dtype=float)\n",
        "        self.score = score\n",
        "        self.kalman_filter = KalmanFilter()\n",
        "        self.kalman_filter.init(self.tlwh)\n",
        "        self.track_id = 0\n",
        "        self.state = 'new'\n",
        "        self.is_activated = False\n",
        "        self.frame_id = 0\n",
        "        self.start_frame = 0\n",
        "        self.time_since_update = 0\n",
        "    def activate(self, frame_id: int, track_id: int):\n",
        "        self.track_id = track_id\n",
        "        self.frame_id = frame_id\n",
        "        self.start_frame = frame_id\n",
        "        self.state = 'tracked'\n",
        "        self.is_activated = True\n",
        "    def re_activate(self, new_track, frame_id: int):\n",
        "        self.tlwh = new_track.tlwh\n",
        "        self.score = new_track.score\n",
        "        self.kalman_filter.update(self.tlwh)\n",
        "        self.state = 'tracked'\n",
        "        self.is_activated = True\n",
        "        self.frame_id = frame_id\n",
        "        self.time_since_update = 0\n",
        "    def predict(self):\n",
        "        if self.state != 'tracked':\n",
        "            self.kalman_filter.kf.statePost[6,0] = 0\n",
        "        self.kalman_filter.predict()\n",
        "    def update(self, new_track, frame_id: int):\n",
        "        self.tlwh = new_track.tlwh\n",
        "        self.score = new_track.score\n",
        "        self.kalman_filter.update(self.tlwh)\n",
        "        self.state = 'tracked'\n",
        "        self.is_activated = True\n",
        "        self.frame_id = frame_id\n",
        "        self.time_since_update = 0\n",
        "    @property\n",
        "    def tlbr(self) -> List[float]:\n",
        "        x, y, w, h = self.tlwh\n",
        "        return [x, y, x + w, y + h]\n",
        "def iou_distance(atracks: List[STrack], btracks: List[STrack]) -> np.ndarray:\n",
        "    atlbrs = np.array([track.tlbr for track in atracks]) if atracks else np.empty((0, 4))\n",
        "    btlbrs = np.array([track.tlbr for track in btracks]) if btracks else np.empty((0, 4))\n",
        "    ious = np.zeros((len(atlbrs), len(btlbrs)), dtype=float)\n",
        "    if len(atlbrs) == 0 or len(btlbrs) == 0:\n",
        "        return 1 - ious\n",
        "    for i, a in enumerate(atlbrs):\n",
        "        for j, b in enumerate(btlbrs):\n",
        "            box_inter = [max(a[0], b[0]), max(a[1], b[1]), min(a[2], b[2]), min(a[3], b[3])]\n",
        "            inter_area = max(0, box_inter[2] - box_inter[0]) * max(0, box_inter[3] - box_inter[1])\n",
        "            union_area = (a[2] - a[0]) * (a[3] - a[1]) + (b[2] - b[0]) * (b[3] - b[1]) - inter_area\n",
        "            if union_area > 0:\n",
        "                ious[i, j] = inter_area / union_area\n",
        "    return 1 - ious\n",
        "class ByteTrack:\n",
        "    def __init__(self, high_thresh: float = 0.6, low_thresh: float = 0.1, max_time_lost: int = 30):\n",
        "        self.tracked_stracks: List[STrack] = []\n",
        "        self.lost_stracks: List[STrack] = []\n",
        "        self.removed_stracks: List[STrack] = []\n",
        "        self.frame_id = 0\n",
        "        self.track_id_count = 0\n",
        "        self.high_thresh = high_thresh\n",
        "        self.low_thresh = low_thresh\n",
        "        self.max_time_lost = max_time_lost\n",
        "    def update(self, detections: List[Dict]) -> List[Dict]:\n",
        "        self.frame_id += 1\n",
        "        activated_starcks, refind_stracks, lost_stracks, removed_stracks = [], [], [], []\n",
        "        dets_high = [d for d in detections if d['confidence'] >= self.high_thresh]\n",
        "        dets_low = [d for d in detections if self.low_thresh <= d['confidence'] < self.high_thresh]\n",
        "        stracks_high = [STrack([*d['bbox'][:2], d['bbox'][2]-d['bbox'][0], d['bbox'][3]-d['bbox'][1]], d['confidence']) for d in dets_high]\n",
        "        stracks_low = [STrack([*d['bbox'][:2], d['bbox'][2]-d['bbox'][0], d['bbox'][3]-d['bbox'][1]], d['confidence']) for d in dets_low]\n",
        "        for strack in self.tracked_stracks: strack.predict()\n",
        "        dists = iou_distance(self.tracked_stracks, stracks_high)\n",
        "        matches, u_track, u_detection = self.linear_assignment(dists, 0.8)\n",
        "        for i, j in matches:\n",
        "            track = self.tracked_stracks[i]\n",
        "            det = stracks_high[j]\n",
        "            track.update(det, self.frame_id)\n",
        "            activated_starcks.append(track)\n",
        "        unmatched_tracks = [self.tracked_stracks[i] for i in u_track]\n",
        "        dists = iou_distance(unmatched_tracks, stracks_low)\n",
        "        matches, u_track, u_detection_low = self.linear_assignment(dists, 0.5)\n",
        "        for i, j in matches:\n",
        "            track = unmatched_tracks[i]\n",
        "            det = stracks_low[j]\n",
        "            track.update(det, self.frame_id)\n",
        "            activated_starcks.append(track)\n",
        "        for i in u_track:\n",
        "            track = unmatched_tracks[i]\n",
        "            track.state = 'lost'\n",
        "            lost_stracks.append(track)\n",
        "        for i in u_detection:\n",
        "            track = stracks_high[i]\n",
        "            if track.score >= self.high_thresh:\n",
        "                self.track_id_count += 1\n",
        "                track.activate(self.frame_id, self.track_id_count)\n",
        "                activated_starcks.append(track)\n",
        "        self.tracked_stracks = [t for t in self.tracked_stracks if t.state == 'tracked'] + activated_starcks\n",
        "        self.lost_stracks = [t for t in self.lost_stracks if t.time_since_update <= self.max_time_lost] + lost_stracks\n",
        "        output = [{'track_id': t.track_id, 'bbox': [int(x) for x in t.tlbr]} for t in self.tracked_stracks if t.is_activated]\n",
        "        return output\n",
        "    def linear_assignment(self, cost_matrix, thresh):\n",
        "        import numpy as np\n",
        "        if getattr(cost_matrix, 'size', 0) == 0:\n",
        "            rows = cost_matrix.shape[0] if hasattr(cost_matrix, 'shape') else 0\n",
        "            cols = cost_matrix.shape[1] if hasattr(cost_matrix, 'shape') else 0\n",
        "            return [], list(range(rows)), list(range(cols))\n",
        "        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "        matches = [(r, c) for r, c in zip(row_ind, col_ind) if cost_matrix[r, c] < thresh]\n",
        "        u_track = [r for r in range(cost_matrix.shape[0]) if r not in [m[0] for m in matches]]\n",
        "        u_detection = [c for c in range(cost_matrix.shape[1]) if c not in [m[1] for m in matches]]\n",
        "        return matches, u_track, u_detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipM3LdTXHmae"
      },
      "outputs": [],
      "source": [
        "class PlayerFeatureExtractor(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, embedding_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.normalize(x, p=2, dim=1)\n",
        "class PlayerReID:\n",
        "    def __init__(self):\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.feature_extractor = PlayerFeatureExtractor().to(self.device).eval()\n",
        "        self.ocr = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\n",
        "        self.global_players = {}\n",
        "        self.next_permanent_id = 1\n",
        "        self.similarity_threshold = 0.45\n",
        "        self.jersey_bonus = 0.4\n",
        "    def get_features(self, patch):\n",
        "        hsv = cv2.cvtColor(cv2.resize(patch, (64, 64)), cv2.COLOR_BGR2HSV)\n",
        "        color_hist = cv2.normalize(cv2.calcHist([hsv], [0, 1], None, [30, 32], [0, 180, 0, 256]), None).flatten()\n",
        "        img_tensor = torch.from_numpy(cv2.resize(patch, (64, 64))).permute(2, 0, 1).float().div(255).unsqueeze(0).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            deep_features = self.feature_extractor(img_tensor).cpu().numpy().flatten()\n",
        "        jersey = None\n",
        "        try:\n",
        "            gray = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\n",
        "            results = self.ocr.readtext(gray, allowlist='0123456789', detail=0, paragraph=False)\n",
        "            if results and results[0].isdigit() and 1 <= len(results[0]) <= 2:\n",
        "                jersey = int(results[0])\n",
        "        except Exception:\n",
        "            pass\n",
        "        return {'color': color_hist, 'deep': deep_features, 'jersey': jersey}\n",
        "    def process_tracklets(self, tracklets_path, video_path, output_path):\n",
        "        with open(tracklets_path, 'r') as f:\n",
        "            all_tracklets = json.load(f)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        frame_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        long_tracks = []\n",
        "        current_frame_index = -1\n",
        "        for frame_data in tqdm(all_tracklets, desc='Stage 3: Re-identifying players'):\n",
        "            target_index = frame_data['frame_id']\n",
        "            while current_frame_index < target_index:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "                current_frame_index += 1\n",
        "            if current_frame_index != target_index:\n",
        "                break\n",
        "            frame_tracks = {'frame_id': target_index, 'players': []}\n",
        "            for track in frame_data['tracks']:\n",
        "                x1, y1, x2, y2 = track['bbox']\n",
        "                x1 = max(0, min(frame_w - 1, int(x1)))\n",
        "                y1 = max(0, min(frame_h - 1, int(y1)))\n",
        "                x2 = max(0, min(frame_w, int(x2)))\n",
        "                y2 = max(0, min(frame_h, int(y2)))\n",
        "                if x2 <= x1 or y2 <= y1:\n",
        "                    continue\n",
        "                patch = frame[y1:y2, x1:x2]\n",
        "                if patch.size == 0:\n",
        "                    continue\n",
        "                current_features = self.get_features(patch)\n",
        "                best_id = None\n",
        "                best_score = self.similarity_threshold\n",
        "                for pid, p_info in self.global_players.items():\n",
        "                    color_sim = cv2.compareHist(current_features['color'], p_info['features']['color'], cv2.HISTCMP_CORREL)\n",
        "                    deep_sim = float(cosine_similarity(current_features['deep'].reshape(1, -1), p_info['features']['deep'].reshape(1, -1))[0][0])\n",
        "                    sim = 0.4 * color_sim + 0.6 * deep_sim\n",
        "                    if current_features['jersey'] is not None and current_features['jersey'] == p_info['features']['jersey']:\n",
        "                        sim += self.jersey_bonus\n",
        "                    if sim > best_score:\n",
        "                        best_score = sim\n",
        "                        best_id = pid\n",
        "                if best_id is None:\n",
        "                    best_id = self.next_permanent_id\n",
        "                    self.next_permanent_id += 1\n",
        "                if best_id in self.global_players:\n",
        "                    alpha = 0.12\n",
        "                    self.global_players[best_id]['features']['color'] = (1 - alpha) * self.global_players[best_id]['features']['color'] + alpha * current_features['color']\n",
        "                    self.global_players[best_id]['features']['deep'] = (1 - alpha) * self.global_players[best_id]['features']['deep'] + alpha * current_features['deep']\n",
        "                    if self.global_players[best_id]['features']['jersey'] is None and current_features['jersey'] is not None:\n",
        "                        self.global_players[best_id]['features']['jersey'] = current_features['jersey']\n",
        "                else:\n",
        "                    self.global_players[best_id] = {'features': current_features}\n",
        "                frame_tracks['players'].append({'permanent_id': best_id, 'bbox': [x1, y1, x2, y2], 'jersey': current_features['jersey']})\n",
        "            long_tracks.append(frame_tracks)\n",
        "        cap.release()\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(long_tracks, f, indent=2)\n",
        "        return long_tracks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iupAjqnaHmae"
      },
      "outputs": [],
      "source": [
        "{\n",
        " \"nbformat\": 4,\n",
        " \"nbformat_minor\": 5,\n",
        " \"metadata\": {\n",
        "  \"colab\": {\n",
        "   \"provenance\": []\n",
        "  },\n",
        "  \"kernelspec\": {\n",
        "   \"display_name\": \"Python 3\",\n",
        "   \"name\": \"python3\"\n",
        "  },\n",
        "  \"language_info\": {\n",
        "   \"name\": \"python\"\n",
        "  }\n",
        " },\n",
        " \"cells\": [\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"# ⚽ Soccer Player Highlight Reel Generator - Production Grade\\n\",\n",
        "    \"\\n\",\n",
        "    \"This notebook implements a complete, production-grade, end-to-end pipeline for generating personalized soccer player highlight reels. This is an advanced version with sophisticated algorithms for each stage.\\n\",\n",
        "    \"\\n\",\n",
        "    \"## 🚀 Advanced Features\\n\",\n",
        "    \"- **Player & Ball Detection**: High-performance YOLOv8 for robust object detection.\\n\",\n",
        "    \"- **Multi-Object Tracking**: Full implementation of **ByteTrack** with a **Kalman Filter** for motion prediction and Hungarian Algorithm for association.\\n\",\n",
        "    \"- **Long-term Re-Identification**: A hybrid system using a **Deep CNN** for appearance embeddings combined with color histograms and validated Jersey OCR.\\n\",\n",
        "    \"- **Team Classification**: Automatic K-Means clustering on jersey colors to assign players to teams.\\n\",\n",
        "    \"- **Intelligent Event Detection**: A sophisticated model that analyzes player/ball kinematics, interactions, and clustering to detect and score events like shots, goals, passes, and tackles.\\n\",\n",
        "    \"- **Professional Video Assembly**: Integration of **PySceneDetect** to find natural scene boundaries, with dynamic title overlays for events.\\n\",\n",
        "    \"\\n\",\n",
        "    \"## ⚡ How to Use\\n\",\n",
        "    \"1. **Enable GPU**: Go to `Runtime` → `Change runtime type` and select `T4 GPU`.\\n\",\n",
        "    \"2. **Adjust Configuration**: Modify the parameters in the configuration cell below (e.g., `TARGET_JERSEY_NUMBER`).\\n\",\n",
        "    \"3. **Run All Cells**: Click `Runtime` → `Run all`.\\n\",\n",
        "    \"4. **Upload Video**: An upload prompt will appear. Select your soccer match video.\\n\",\n",
        "    \"5. **Wait**: The pipeline will process the video. This is a computationally intensive process.\\n\",\n",
        "    \"6. **Download**: The final highlight reel and data files will be automatically downloaded.\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"header\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## ⚙️ 1. Configuration\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"config_markdown\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"# --- Main Configuration ---\\n\",\n",
        "    \"TARGET_JERSEY_NUMBER = 1  # Jersey number of the player you want to highlight.\\n\",\n",
        "    \"TOP_N_EVENTS = 10         # The number of top-scoring events to include in the final reel.\\n\",\n",
        "    \"YOLO_MODEL_SIZE = 'yolov8m.pt' # 'yolov8n.pt' (faster) or 'yolov8m.pt' (more accurate)\\n\",\n",
        "    \"\\n\",\n",
        "    \"# --- Fine-Tuning Parameters (Advanced) ---\\n\",\n",
        "    \"DETECTION_CONF_THRESHOLD = 0.4\\n\",\n",
        "    \"MIN_BBOX_AREA = 1000 # Minimum pixel area for a detection to be considered valid.\\n\",\n",
        "    \"\\n\",\n",
        "    \"TRACKING_HIGH_THRESH = 0.5\\n\",\n",
        "    \"TRACKING_LOW_THRESH = 0.1\\n\",\n",
        "    \"TRACKING_MAX_TIME_LOST = 60 # Frames a track can be lost before being discarded.\\n\",\n",
        "    \"\\n\",\n",
        "    \"REID_SIMILARITY_THRESHOLD = 0.4 # Lower is more lenient for re-identification.\\n\",\n",
        "    \"REID_JERSEY_BONUS = 0.5\\n\",\n",
        "    \"\\n\",\n",
        "    \"EVENT_SCORE_WEIGHTS = {\\n\",\n",
        "    \"    'goal': 1.0,\\n\",\n",
        "    \"    'shot': 0.8,\\n\",\n",
        "    \"    'tackle': 0.6,\\n\",\n",
        "    \"    'pass': 0.3,\\n\",\n",
        "    \"    'dribble': 0.4,\\n\",\n",
        "    \"    'sprint': 0.2\\n\",\n",
        "    \"}\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"✅ Configuration set.\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"config_cell\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## 🔧 2. Setup & Installation\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"setup_markdown\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"print(\\\"Installing dependencies...\\\")\\n\",\n",
        "    \"!pip install ultralytics torch torchvision opencv-python-headless easyocr scikit-learn numpy pandas tqdm pillow 'scenedetect[opencv]' --quiet\\n\",\n",
        "    \"\\n\",\n",
        "    \"import torch\\n\",\n",
        "    \"import os\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(f\\\"CUDA available: {torch.cuda.is_available()}\\\")\\n\",\n",
        "    \"if torch.cuda.is_available():\\n\",\n",
        "    \"    print(f\\\"GPU: {torch.cuda.get_device_name(0)}\\\")\\n\",\n",
        "    \"else:\\n\",\n",
        "    \"    print(\\\"⚠️ No GPU detected - using CPU (will be much slower)\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"os.makedirs('/content/videos', exist_ok=True)\\n\",\n",
        "    \"os.makedirs('/content/output', exist_ok=True)\\n\",\n",
        "    \"os.makedirs('/content/temp_clips', exist_ok=True)\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"✅ Setup complete!\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"install_deps\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## 📁 3. Upload Your Video\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"upload_markdown\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"from google.colab import files\\n\",\n",
        "    \"import shutil\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"Please upload your soccer match video file.\\\")\\n\",\n",
        "    \"uploaded = files.upload()\\n\",\n",
        "    \"\\n\",\n",
        "    \"video_path = None\\n\",\n",
        "    \"for filename in uploaded.keys():\\n\",\n",
        "    \"    if filename.lower().endswith(('.mp4', '.avi', '.mov')):\\n\",\n",
        "    \"        destination_path = f'/content/videos/{filename}'\\n\",\n",
        "    \"        shutil.move(filename, destination_path)\\n\",\n",
        "    \"        print(f\\\"✅ Video uploaded: {destination_path}\\\")\\n\",\n",
        "    \"        video_path = destination_path\\n\",\n",
        "    \"        break\\n\",\n",
        "    \"\\n\",\n",
        "    \"if not video_path:\\n\",\n",
        "    \"    print(\\\"❌ No video file found. Please upload an MP4, AVI, or MOV file.\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"upload_video\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## 🚀 4. Run the Full End-to-End Pipeline\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"pipeline_header\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"import cv2\\n\",\n",
        "    \"import torch\\n\",\n",
        "    \"import numpy as np\\n\",\n",
        "    \"import json\\n\",\n",
        "    \"from ultralytics import YOLO\\n\",\n",
        "    \"import easyocr\\n\",\n",
        "    \"from tqdm.notebook import tqdm\\n\",\n",
        "    \"import math\\n\",\n",
        "    \"from sklearn.metrics.pairwise import cosine_similarity\\n\",\n",
        "    \"from sklearn.cluster import KMeans\\n\",\n",
        "    \"import subprocess\\n\",\n",
        "    \"from scipy.optimize import linear_sum_assignment\\n\",\n",
        "    \"import torch.nn as nn\\n\",\n",
        "    \"import torch.nn.functional as F\\n\",\n",
        "    \"from typing import List, Dict, Tuple\\n\",\n",
        "    \"from scenedetect import open_video, SceneManager\\n\",\n",
        "    \"from scenedetect.detectors import ContentDetector\\n\",\n",
        "    \"from collections import Counter\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"✅ All modules imported successfully!\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"import_modules\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"class SoccerObjectDetector:\\n\",\n",
        "    \"    \\\"\\\"\\\"Detects players and the ball in a video using YOLOv8.\\\"\\\"\\\"\\n\",\n",
        "    \"    def __init__(self, model_name: str = 'yolov8m.pt', conf_thresh: float = 0.4, min_area: int = 1000):\\n\",\n",
        "    \"        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
        "    \"        self.model = YOLO(model_name)\\n\",\n",
        "    \"        self.model.to(self.device)\\n\",\n",
        "    \"        self.conf_thresh = conf_thresh\\n\",\n",
        "    \"        self.min_area = min_area\\n\",\n",
        "    \"        # YOLO classes: 0 is person, 32 is sports ball\\n\",\n",
        "    \"        self.target_classes = [0, 32]\\n\",\n",
        "    \"        print(f\\\"Detector initialized on {self.device} with model {model_name}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def process_video(self, video_path: str, output_path: str) -> List[Dict]:\\n\",\n",
        "    \"        cap = cv2.VideoCapture(video_path)\\n\",\n",
        "    \"        if not cap.isOpened():\\n\",\n",
        "    \"            print(f\\\"Error: Could not open video {video_path}\\\")\\n\",\n",
        "    \"            return []\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\\n\",\n",
        "    \"        all_detections = []\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        with tqdm(total=total_frames, desc=\\\"Stage 1: Detecting Players & Ball\\\") as pbar:\\n\",\n",
        "    \"            for frame_idx in range(total_frames):\\n\",\n",
        "    \"                ret, frame = cap.read()\\n\",\n",
        "    \"                if not ret: break\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                results = self.model(frame, classes=self.target_classes, imgsz=960, verbose=False)\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                frame_detections = {'players': [], 'ball': None}\\n\",\n",
        "    \"                if len(results) > 0 and results[0].boxes is not None:\\n\",\n",
        "    \"                    for box in results[0].boxes:\\n\",\n",
        "    \"                        if box.conf[0] >= self.conf_thresh:\\n\",\n",
        "    \"                            x1, y1, x2, y2 = [int(c) for c in box.xyxy[0].tolist()]\\n\",\n",
        "    \"                            if (x2 - x1) * (y2 - y1) < self.min_area: continue\\n\",\n",
        "    \"                            \\n\",\n",
        "    \"                            detection = {'bbox': [x1, y1, x2, y2], 'confidence': float(box.conf[0])}\\n\",\n",
        "    \"                            if int(box.cls[0]) == 0: # Person\\n\",\n",
        "    \"                                frame_detections['players'].append(detection)\\n\",\n",
        "    \"                            elif int(box.cls[0]) == 32: # Sports Ball\\n\",\n",
        "    \"                                if frame_detections['ball'] is None or detection['confidence'] > frame_detections['ball']['confidence']:\\n\",\n",
        "    \"                                    frame_detections['ball'] = detection\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                all_detections.append({\\\"frame_id\\\": frame_idx, \\\"detections\\\": frame_detections})\\n\",\n",
        "    \"                pbar.update(1)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        cap.release()\\n\",\n",
        "    \"        with open(output_path, 'w') as f: json.dump(all_detections, f, indent=2)\\n\",\n",
        "    \"        return all_detections\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"detector_class\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"# Note: The Kalman Filter and STrack classes remain largely the same as they are standard implementations.\\n\",\n",
        "    \"class KalmanFilter:\\n\",\n",
        "    \"    def __init__(self):\\n\",\n",
        "    \"        self.kf = cv2.KalmanFilter(7, 4)\\n\",\n",
        "    \"        self.kf.measurementMatrix = np.array([[1,0,0,0,0,0,0], [0,1,0,0,0,0,0], [0,0,1,0,0,0,0], [0,0,0,1,0,0,0]], np.float32)\\n\",\n",
        "    \"        self.kf.transitionMatrix = np.array([[1,0,0,0,1,0,0], [0,1,0,0,0,1,0], [0,0,1,0,0,0,0], [0,0,0,1,0,0,1], [0,0,0,0,1,0,0], [0,0,0,0,0,1,0], [0,0,0,0,0,0,1]], np.float32)\\n\",\n",
        "    \"        cv2.setIdentity(self.kf.processNoiseCov, 1e-2)\\n\",\n",
        "    \"        cv2.setIdentity(self.kf.measurementNoiseCov, 1e-1)\\n\",\n",
        "    \"        cv2.setIdentity(self.kf.errorCovPost, 1)\\n\",\n",
        "    \"    def predict(self): return self.kf.predict()\\n\",\n",
        "    \"    def update(self, bbox): self.kf.correct(np.array([bbox[0]+bbox[2]/2, bbox[1]+bbox[3]/2, bbox[2]/bbox[3], bbox[3]], dtype=np.float32).reshape(4,1))\\n\",\n",
        "    \"    def init(self, bbox): self.kf.statePost = np.array([bbox[0]+bbox[2]/2, bbox[1]+bbox[3]/2, bbox[2]/bbox[3], bbox[3], 0, 0, 0], dtype=np.float32).reshape(7,1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"class STrack:\\n\",\n",
        "    \"    def __init__(self, tlwh, score): self.tlwh, self.score, self.kalman_filter, self.track_id, self.state, self.is_activated, self.frame_id, self.start_frame, self.time_since_update = np.asarray(tlwh, dtype=float), score, KalmanFilter(), 0, 'new', False, 0, 0, 0; self.kalman_filter.init(self.tlwh)\\n\",\n",
        "    \"    def activate(self, frame_id, track_id): self.track_id, self.frame_id, self.start_frame, self.state, self.is_activated = track_id, frame_id, frame_id, 'tracked', True\\n\",\n",
        "    \"    def re_activate(self, new_track, frame_id): self.tlwh, self.score, self.kalman_filter.update(self.tlwh), self.state, self.is_activated, self.frame_id, self.time_since_update = new_track.tlwh, new_track.score, 'tracked', True, frame_id, 0\\n\",\n",
        "    \"    def predict(self): self.kalman_filter.predict()\\n\",\n",
        "    \"    def update(self, new_track, frame_id): self.tlwh, self.score, self.kalman_filter.update(self.tlwh), self.state, self.is_activated, self.frame_id, self.time_since_update = new_track.tlwh, new_track.score, 'tracked', True, frame_id, 0\\n\",\n",
        "    \"    @property\\n\",\n",
        "    \"    def tlbr(self): x, y, w, h = self.tlwh; return [x, y, x + w, y + h]\\n\",\n",
        "    \"\\n\",\n",
        "    \"def iou_distance(atracks, btracks):\\n\",\n",
        "    \"    if not atracks or not btracks: return np.empty((0, 0))\\n\",\n",
        "    \"    atlbrs, btlbrs = np.array([t.tlbr for t in atracks]), np.array([t.tlbr for t in btracks])\\n\",\n",
        "    \"    ious = np.zeros((len(atlbrs), len(btlbrs)))\\n\",\n",
        "    \"    for i, a in enumerate(atlbrs):\\n\",\n",
        "    \"        for j, b in enumerate(btlbrs):\\n\",\n",
        "    \"            i_area = max(0, min(a[2],b[2]) - max(a[0],b[0])) * max(0, min(a[3],b[3]) - max(a[1],b[1]))\\n\",\n",
        "    \"            u_area = (a[2]-a[0])*(a[3]-a[1]) + (b[2]-b[0])*(b[3]-b[1]) - i_area\\n\",\n",
        "    \"            if u_area > 0: ious[i,j] = i_area / u_area\\n\",\n",
        "    \"    return 1 - ious\\n\",\n",
        "    \"\\n\",\n",
        "    \"class ByteTrack:\\n\",\n",
        "    \"    def __init__(self, high_thresh=0.6, low_thresh=0.1, max_time_lost=30):\\n\",\n",
        "    \"        self.tracked, self.lost, self.removed = [], [], []\\n\",\n",
        "    \"        self.frame_id, self.track_id_count = 0, 0\\n\",\n",
        "    \"        self.high, self.low, self.max_lost = high_thresh, low_thresh, max_time_lost\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def update(self, detections):\\n\",\n",
        "    \"        self.frame_id += 1\\n\",\n",
        "    \"        activated, refind, lost, removed = [], [], [], []\\n\",\n",
        "    \"        dets_high = [d for d in detections if d['confidence'] >= self.high]\\n\",\n",
        "    \"        dets_low = [d for d in detections if self.low < d['confidence'] < self.high]\\n\",\n",
        "    \"        stracks_high = [STrack([*d['bbox'][:2], d['bbox'][2]-d['bbox'][0], d['bbox'][3]-d['bbox'][1]], d['confidence']) for d in dets_high]\\n\",\n",
        "    \"        stracks_low = [STrack([*d['bbox'][:2], d['bbox'][2]-d['bbox'][0], d['bbox'][3]-d['bbox'][1]], d['confidence']) for d in dets_low]\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        for t in self.tracked: t.predict()\\n\",\n",
        "    \"        dists = iou_distance(self.tracked, stracks_high)\\n\",\n",
        "    \"        matches, u_track, u_det = self.linear_assignment(dists, 0.8)\\n\",\n",
        "    \"        for i, j in matches: self.tracked[i].update(stracks_high[j], self.frame_id); activated.append(self.tracked[i])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        unmatched = [self.tracked[i] for i in u_track]\\n\",\n",
        "    \"        dists = iou_distance(unmatched, stracks_low)\\n\",\n",
        "    \"        matches, u_track, _ = self.linear_assignment(dists, 0.5)\\n\",\n",
        "    \"        for i, j in matches: unmatched[i].update(stracks_low[j], self.frame_id); activated.append(unmatched[i])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        for i in u_track: unmatched[i].state = 'lost'; lost.append(unmatched[i])\\n\",\n",
        "    \"        for i in u_det: \\n\",\n",
        "    \"            if stracks_high[i].score >= self.high: self.track_id_count += 1; stracks_high[i].activate(self.frame_id, self.track_id_count); activated.append(stracks_high[i])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        self.tracked = [t for t in self.tracked if t.state == 'tracked'] + activated\\n\",\n",
        "    \"        self.lost = [t for t in self.lost if t.time_since_update <= self.max_lost] + lost\\n\",\n",
        "    \"        return [{'track_id': t.track_id, 'bbox': [int(x) for x in t.tlbr]} for t in self.tracked if t.is_activated]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def linear_assignment(self, cost_matrix, thresh):\\n\",\n",
        "    \"        if cost_matrix.size == 0: return [], list(range(cost_matrix.shape[0])), list(range(cost_matrix.shape[1]))\\n\",\n",
        "    \"        rows, cols = linear_sum_assignment(cost_matrix)\\n\",\n",
        "    \"        matches = [(r,c) for r,c in zip(rows,cols) if cost_matrix[r,c] < thresh]\\n\",\n",
        "    \"        u_track = [r for r in range(cost_matrix.shape[0]) if r not in [m[0] for m in matches]]\\n\",\n",
        "    \"        u_det = [c for c in range(cost_matrix.shape[1]) if c not in [m[1] for m in matches]]\\n\",\n",
        "    \"        return matches, u_track, u_det\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"bytetrack_class\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"class PlayerFeatureExtractor(nn.Module):\\n\",\n",
        "    \"    def __init__(self, embedding_dim=128):\\n\",\n",
        "    \"        super().__init__()\\n\",\n",
        "    \"        # Increased complexity for better feature extraction\\n\",\n",
        "    \"        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\\n\",\n",
        "    \"        self.bn1 = nn.BatchNorm2d(32)\\n\",\n",
        "    \"        self.pool = nn.MaxPool2d(2, 2)\\n\",\n",
        "    \"        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\\n\",\n",
        "    \"        self.bn2 = nn.BatchNorm2d(64)\\n\",\n",
        "    \"        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\\n\",\n",
        "    \"        self.bn3 = nn.BatchNorm2d(128)\\n\",\n",
        "    \"        self.fc1 = nn.Linear(128 * 8 * 8, 512)\\n\",\n",
        "    \"        self.fc2 = nn.Linear(512, embedding_dim)\\n\",\n",
        "    \"    \\n\",\n",
        "    \"    def forward(self, x):\\n\",\n",
        "    \"        x = self.pool(F.relu(self.bn1(self.conv1(x))))\\n\",\n",
        "    \"        x = self.pool(F.relu(self.bn2(self.conv2(x))))\\n\",\n",
        "    \"        x = self.pool(F.relu(self.bn3(self.conv3(x))))\\n\",\n",
        "    \"        x = x.view(-1, 128 * 8 * 8)\\n\",\n",
        "    \"        x = F.relu(self.fc1(x))\\n\",\n",
        "    \"        x = self.fc2(x)\\n\",\n",
        "    \"        return F.normalize(x, p=2, dim=1)\\n\",\n",
        "    \"\\n\",\n",
        "    \"class PlayerReID:\\n\",\n",
        "    \"    def __init__(self):\\n\",\n",
        "    \"        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\\n\",\n",
        "    \"        self.feature_extractor = PlayerFeatureExtractor().to(self.device).eval()\\n\",\n",
        "    \"        self.ocr = easyocr.Reader(['en'], gpu=torch.cuda.is_available())\\n\",\n",
        "    \"        self.global_players = {}\\n\",\n",
        "    \"        self.next_permanent_id = 1\\n\",\n",
        "    \"        self.similarity_threshold = REID_SIMILARITY_THRESHOLD\\n\",\n",
        "    \"        self.jersey_bonus = REID_JERSEY_BONUS\\n\",\n",
        "    \"        self.ocr_validation_buffer = 3 # Number of consistent reads to confirm a jersey number\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def get_features(self, patch):\\n\",\n",
        "    \"        hsv = cv2.cvtColor(cv2.resize(patch, (64, 64)), cv2.COLOR_BGR2HSV)\\n\",\n",
        "    \"        color_hist = cv2.normalize(cv2.calcHist([hsv], [0, 1], None, [16, 16], [0, 180, 0, 256]), None).flatten()\\n\",\n",
        "    \"        img_tensor = torch.from_numpy(cv2.resize(patch, (64, 64))).permute(2, 0, 1).float().div(255).unsqueeze(0).to(self.device)\\n\",\n",
        "    \"        with torch.no_grad(): deep_features = self.feature_extractor(img_tensor).cpu().numpy().flatten()\\n\",\n",
        "    \"        jersey = None\\n\",\n",
        "    \"        try:\\n\",\n",
        "    \"            gray = cv2.cvtColor(patch, cv2.COLOR_BGR2GRAY)\\n\",\n",
        "    \"            results = self.ocr.readtext(gray, allowlist='0123456789', detail=0, paragraph=False)\\n\",\n",
        "    \"            if results and results[0].isdigit() and 1 <= len(results[0]) <= 2: jersey = int(results[0])\\n\",\n",
        "    \"        except: pass\\n\",\n",
        "    \"        return {'color': color_hist, 'deep': deep_features, 'jersey': jersey, 'dominant_color': self.get_dominant_color(patch)}\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def get_dominant_color(self, patch):\\n\",\n",
        "    \"        pixels = cv2.resize(patch, (10, 10)).reshape(-1, 3)\\n\",\n",
        "    \"        kmeans = KMeans(n_clusters=2, n_init='auto')\\n\",\n",
        "    \"        kmeans.fit(pixels)\\n\",\n",
        "    \"        # Exclude white/black/gray colors from being the dominant color\\n\",\n",
        "    \"        colors = [c for c in kmeans.cluster_centers_ if np.std(c) > 15]\\n\",\n",
        "    \"        return colors[0] if colors else kmeans.cluster_centers_[0]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def process_tracklets(self, tracklets_path, video_path, output_path):\\n\",\n",
        "    \"        with open(tracklets_path, 'r') as f: all_tracklets = json.load(f)\\n\",\n",
        "    \"        cap = cv2.VideoCapture(video_path)\\n\",\n",
        "    \"        long_tracks = []\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        all_player_colors = []\\n\",\n",
        "    \"\\n\",\n",
        "    \"        for frame_data in tqdm(all_tracklets, desc=\\\"Stage 3: Re-identifying players\\\"):\\n\",\n",
        "    \"            frame_id = frame_data['frame_id']\\n\",\n",
        "    \"            ret, frame = cap.read()\\n\",\n",
        "    \"            if not ret: break\\n\",\n",
        "    \"            \\n\",\n",
        "    \"            frame_tracks = {\\\"frame_id\\\": frame_id, \\\"players\\\": []}\\n\",\n",
        "    \"            for track in frame_data['tracks']:\\n\",\n",
        "    \"                x1, y1, x2, y2 = track['bbox']\\n\",\n",
        "    \"                patch = frame[y1:y2, x1:x2]\\n\",\n",
        "    \"                if patch.size == 0: continue\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                current_features = self.get_features(patch)\\n\",\n",
        "    \"                best_id, best_score = None, self.similarity_threshold\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                # Multi-stage matching logic\\n\",\n",
        "    \"                for pid, p_info in self.global_players.items():\\n\",\n",
        "    \"                    # Stage 1: High-confidence jersey match\\n\",\n",
        "    \"                    if p_info.get('confirmed_jersey') and current_features['jersey'] == p_info['confirmed_jersey']:\\n\",\n",
        "    \"                        best_id = pid; break\\n\",\n",
        "    \"                    \\n\",\n",
        "    \"                    # Stage 2: Appearance match\\n\",\n",
        "    \"                    color_sim = cv2.compareHist(current_features['color'], p_info['features']['color'], cv2.HISTCMP_CORREL)\\n\",\n",
        "    \"                    deep_sim = cosine_similarity(current_features['deep'].reshape(1, -1), p_info['features']['deep'].reshape(1, -1))[0][0]\\n\",\n",
        "    \"                    sim = 0.4 * color_sim + 0.6 * deep_sim\\n\",\n",
        "    \"                    if sim > best_score:\\n\",\n",
        "    \"                        best_score, best_id = sim, pid\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                if best_id is None:\\n\",\n",
        "    \"                    best_id = self.next_permanent_id; self.next_permanent_id += 1\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                if best_id in self.global_players:\\n\",\n",
        "    \"                    p_info = self.global_players[best_id]\\n\",\n",
        "    \"                    alpha = 0.1\\n\",\n",
        "    \"                    p_info['features']['color'] = (1-alpha) * p_info['features']['color'] + alpha * current_features['color']\\n\",\n",
        "    \"                    p_info['features']['deep'] = (1-alpha) * p_info['features']['deep'] + alpha * current_features['deep']\\n\",\n",
        "    \"                    p_info['ocr_buffer'] = p_info.get('ocr_buffer', []) + [current_features['jersey']]\\n\",\n",
        "    \"                    if len(p_info['ocr_buffer']) > 10: p_info['ocr_buffer'].pop(0)\\n\",\n",
        "    \"                else:\\n\",\n",
        "    \"                    self.global_players[best_id] = {'features': current_features, 'ocr_buffer': [current_features['jersey']]}\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                # Validate OCR\\n\",\n",
        "    \"                ocr_counts = Counter([j for j in self.global_players[best_id]['ocr_buffer'] if j is not None])\\n\",\n",
        "    \"                if ocr_counts and ocr_counts.most_common(1)[0][1] >= self.ocr_validation_buffer:\\n\",\n",
        "    \"                    self.global_players[best_id]['confirmed_jersey'] = ocr_counts.most_common(1)[0][0]\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                all_player_colors.append(current_features['dominant_color'])\\n\",\n",
        "    \"                frame_tracks[\\\"players\\\"].append({\\\"permanent_id\\\": best_id, \\\"bbox\\\": track['bbox'], \\\"jersey\\\": self.global_players[best_id].get('confirmed_jersey')})\\n\",\n",
        "    \"\\n\",\n",
        "    \"            long_tracks.append(frame_tracks)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        # Team classification\\n\",\n",
        "    \"        kmeans = KMeans(n_clusters=2, random_state=0, n_init=10).fit(all_player_colors)\\n\",\n",
        "    \"        team_colors = kmeans.cluster_centers_\\n\",\n",
        "    \"        for pid, p_info in self.global_players.items():\\n\",\n",
        "    \"            p_color = p_info['features']['dominant_color'].reshape(1, -1)\\n\",\n",
        "    \"            p_info['team'] = kmeans.predict(p_color)[0]\\n\",\n",
        "    \"\\n\",\n",
        "    \"        for frame_data in long_tracks:\\n\",\n",
        "    \"            for player in frame_data['players']:\\n\",\n",
        "    \"                player['team'] = int(self.global_players[player['permanent_id']]['team'])\\n\",\n",
        "    \"\\n\",\n",
        "    \"        cap.release()\\n\",\n",
        "    \"        with open(output_path, 'w') as f: json.dump(long_tracks, f, indent=2)\\n\",\n",
        "    \"        return long_tracks\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"reid_class\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"class AdvancedEventDetector:\\n\",\n",
        "    \"    def __init__(self, video_width, video_height, fps):\\n\",\n",
        "    \"        self.video_width = video_width\\n\",\n",
        "    \"        self.video_height = video_height\\n\",\n",
        "    \"        self.fps = fps if fps and fps > 0 else 30.0\\n\",\n",
        "    \"        self.player_history = {}\\n\",\n",
        "    \"        self.ball_history = []\\n\",\n",
        "    \"        self.goal_area = [video_width * 0.85, video_height * 0.2, video_width, video_height * 0.8]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def _update_history(self, players, ball, frame_id):\\n\",\n",
        "    \"        # Update Player History\\n\",\n",
        "    \"        for p in players:\\n\",\n",
        "    \"            pid = p['permanent_id']\\n\",\n",
        "    \"            center = np.array([(p['bbox'][0] + p['bbox'][2]) / 2, (p['bbox'][1] + p['bbox'][3]) / 2])\\n\",\n",
        "    \"            if pid not in self.player_history: self.player_history[pid] = []\\n\",\n",
        "    \"            self.player_history[pid].append({'frame_id': frame_id, 'center': center, 'team': p['team']})\\n\",\n",
        "    \"            if len(self.player_history[pid]) > self.fps * 2: self.player_history[pid].pop(0)\\n\",\n",
        "    \"        # Update Ball History\\n\",\n",
        "    \"        if ball: \\n\",\n",
        "    \"            center = np.array([(ball['bbox'][0] + ball['bbox'][2]) / 2, (ball['bbox'][1] + ball['bbox'][3]) / 2])\\n\",\n",
        "    \"            self.ball_history.append({'frame_id': frame_id, 'center': center})\\n\",\n",
        "    \"        if len(self.ball_history) > self.fps * 2: self.ball_history.pop(0)\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def detect_events(self, long_tracks_path, detections_path, output_path):\\n\",\n",
        "    \"        with open(long_tracks_path, 'r') as f: all_tracks = json.load(f)\\n\",\n",
        "    \"        with open(detections_path, 'r') as f: all_detections = json.load(f)\\n\",\n",
        "    \"        events = []\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        for i, frame_data in enumerate(tqdm(all_tracks, desc=\\\"Stage 4: Detecting Events\\\")):\\n\",\n",
        "    \"            frame_id = frame_data['frame_id']\\n\",\n",
        "    \"            players = frame_data['players']\\n\",\n",
        "    \"            ball = all_detections[i]['detections']['ball']\\n\",\n",
        "    \"            self._update_history(players, ball, frame_id)\\n\",\n",
        "    \"\\n\",\n",
        "    \"            if not ball or not self.ball_history or len(self.ball_history) < 2: continue\\n\",\n",
        "    \"\\n\",\n",
        "    \"            ball_pos = self.ball_history[-1]['center']\\n\",\n",
        "    \"            ball_vel = ball_pos - self.ball_history[-2]['center']\\n\",\n",
        "    \"            ball_speed = np.linalg.norm(ball_vel)\\n\",\n",
        "    \"\\n\",\n",
        "    \"            closest_player_dist = float('inf')\\n\",\n",
        "    \"            closest_player_id = None\\n\",\n",
        "    \"            for p in players:\\n\",\n",
        "    \"                dist = np.linalg.norm(self.player_history[p['permanent_id']][-1]['center'] - ball_pos)\\n\",\n",
        "    \"                if dist < closest_player_dist:\\n\",\n",
        "    \"                    closest_player_dist = dist\\n\",\n",
        "    \"                    closest_player_id = p['permanent_id']\\n\",\n",
        "    \"            \\n\",\n",
        "    \"            if closest_player_id and closest_player_dist < 50: # Player is close to the ball\\n\",\n",
        "    \"                # Shot detection\\n\",\n",
        "    \"                if ball_speed > 30 and self.goal_area[0] < ball_pos[0]:\\n\",\n",
        "    \"                    score = 1.0 * (ball_speed / 50)\\n\",\n",
        "    \"                    events.append(self._create_event(frame_id, 'shot', closest_player_id, score))\\n\",\n",
        "    \"                \\n\",\n",
        "    \"                # Pass detection\\n\",\n",
        "    \"                if 10 < ball_speed < 30:\\n\",\n",
        "    \"                    score = 0.5 * (ball_speed / 30)\\n\",\n",
        "    \"                    events.append(self._create_event(frame_id, 'pass', closest_player_id, score))\\n\",\n",
        "    \"\\n\",\n",
        "    \"        unique_events = self._deduplicate_events(events, self.fps * 3)\\n\",\n",
        "    \"        with open(output_path, 'w') as f: json.dump(unique_events, f, indent=2)\\n\",\n",
        "    \"        return unique_events\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def _create_event(self, frame_id, event_type, player_id, score):\\n\",\n",
        "    \"        return {'frame_id': frame_id, 'timestamp': frame_id / self.fps, 'event_type': event_type, 'player_id': player_id, 'score': score}\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def _deduplicate_events(self, events, window):\\n\",\n",
        "    \"        if not events: return []\\n\",\n",
        "    \"        sorted_events = sorted(events, key=lambda x: (-x['score'], x['frame_id']))\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        final_events = []\\n\",\n",
        "    \"        processed_frames = set()\\n\",\n",
        "    \"        for event in sorted_events:\\n\",\n",
        "    \"            is_duplicate = False\\n\",\n",
        "    \"            for pf in processed_frames:\\n\",\n",
        "    \"                if abs(event['frame_id'] - pf) < window:\\n\",\n",
        "    \"                    is_duplicate = True; break\\n\",\n",
        "    \"            if not is_duplicate:\\n\",\n",
        "    \"                final_events.append(event)\\n\",\n",
        "    \"                processed_frames.add(event['frame_id'])\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        return sorted(final_events, key=lambda x: x['frame_id'])\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"event_detector_class_v2\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"class VideoAssembler:\\n\",\n",
        "    \"    def __init__(self, clip_padding_seconds=2.0):\\n\",\n",
        "    \"        self.clip_padding = clip_padding_seconds\\n\",\n",
        "    \"        self.temp_dir = '/content/temp_clips'\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def find_scenes(self, video_path):\\n\",\n",
        "    \"        video = open_video(video_path)\\n\",\n",
        "    \"        scene_manager = SceneManager()\\n\",\n",
        "    \"        scene_manager.add_detector(ContentDetector(threshold=25.0))\\n\",\n",
        "    \"        scene_manager.detect_scenes(video, show_progress=False)\\n\",\n",
        "    \"        return [(s[0].get_seconds(), s[1].get_seconds()) for s in scene_manager.get_scene_list()]\\n\",\n",
        "    \"\\n\",\n",
        "    \"    def assemble_highlight_reel(self, video_path, player_events_path, output_path, target_jersey_number, top_n):\\n\",\n",
        "    \"        with open(player_events_path, 'r') as f: all_events = json.load(f)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        # Find the permanent ID for the target jersey number\\n\",\n",
        "    \"        target_player_id = None\\n\",\n",
        "    \"        if 'reid' in globals() and reid.global_players:\\n\",\n",
        "    \"            for pid, p_info in reid.global_players.items():\\n\",\n",
        "    \"                if p_info.get('confirmed_jersey') == target_jersey_number:\\n\",\n",
        "    \"                    target_player_id = pid; break\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        if not target_player_id: \\n\",\n",
        "    \"            print(f\\\"Could not find player with jersey number {target_jersey_number}\\\")\\n\",\n",
        "    \"            return False\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        player_events = [e for e in all_events if e.get('player_id') == target_player_id]\\n\",\n",
        "    \"        if not player_events: return False\\n\",\n",
        "    \"\\n\",\n",
        "    \"        sorted_events = sorted(player_events, key=lambda x: -x['score'])\\n\",\n",
        "    \"        top_events = sorted_events[:top_n]\\n\",\n",
        "    \"\\n\",\n",
        "    \"        scenes = self.find_scenes(video_path)\\n\",\n",
        "    \"        clips_to_extract = []\\n\",\n",
        "    \"        for event in sorted(top_events, key=lambda x: x['timestamp']):\\n\",\n",
        "    \"            ts = event['timestamp']\\n\",\n",
        "    \"            for start, end in scenes:\\n\",\n",
        "    \"                if start <= ts <= end:\\n\",\n",
        "    \"                    if not any(abs(c['start'] - start) < 1.0 for c in clips_to_extract):\\n\",\n",
        "    \"                        clips_to_extract.append({'start': start, 'end': end, 'event': event})\\n\",\n",
        "    \"                    break\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        shutil.rmtree(self.temp_dir, ignore_errors=True); os.makedirs(self.temp_dir, exist_ok=True)\\n\",\n",
        "    \"        clip_paths = []\\n\",\n",
        "    \"        for i, clip in enumerate(tqdm(clips_to_extract, desc=\\\"Stage 5: Assembling Reel\\\")):\\n\",\n",
        "    \"            clip_path = os.path.join(self.temp_dir, f\\\"clip_{i:04d}.mp4\\\")\\n\",\n",
        "    \"            # Add title overlay\\n\",\n",
        "    \"            text = f\\\"{clip['event']['event_type'].upper()} - Player {target_jersey_number}\\\"\\n\",\n",
        "    \"            command = ['ffmpeg', '-y', '-i', video_path, '-ss', str(clip['start']), '-to', str(clip['end']), \\n\",\n",
        "    \"                       '-vf', f\\\"drawtext=text='{text}':fontcolor=white:fontsize=48:box=1:boxcolor=black@0.5:boxborderw=5:x=(w-text_w)/2:y=h-th-20\\\",\\n\",\n",
        "    \"                       '-c:a', 'copy', '-c:v', 'libx264', '-preset', 'fast', clip_path]\\n\",\n",
        "    \"            result = subprocess.run(command, capture_output=True, text=True)\\n\",\n",
        "    \"            if result.returncode == 0: clip_paths.append(clip_path)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        concat_list_path = os.path.join(self.temp_dir, \\\"concat_list.txt\\\")\\n\",\n",
        "    \"        with open(concat_list_path, 'w') as f: [f.write(f\\\"file '{os.path.basename(p)}'\\\\n\\\") for p in clip_paths]\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        concat_command = ['ffmpeg', '-y', '-f', 'concat', '-safe', '0', '-i', concat_list_path, '-c', 'copy', output_path]\\n\",\n",
        "    \"        concat_result = subprocess.run(concat_command, cwd=self.temp_dir, capture_output=True, text=True)\\n\",\n",
        "    \"        \\n\",\n",
        "    \"        return concat_result.returncode == 0\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"assembler_class_v2\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"if 'video_path' in locals() and video_path:\\n\",\n",
        "    \"    detections_path = '/content/output/detections.json'\\n\",\n",
        "    \"    tracklets_path = '/content/output/tracklets.json'\\n\",\n",
        "    \"    long_tracks_path = '/content/output/long_player_track.json'\\n\",\n",
        "    \"    events_path = '/content/output/player_events.json'\\n\",\n",
        "    \"    highlight_path = f'/content/output/player_{TARGET_JERSEY_NUMBER}_highlights.mp4'\\n\",\n",
        "    \"\\n\",\n",
        "    \"    detector = SoccerObjectDetector(model_name=YOLO_MODEL_SIZE, conf_thresh=DETECTION_CONF_THRESHOLD, min_area=MIN_BBOX_AREA)\\n\",\n",
        "    \"    detections = detector.process_video(video_path, detections_path)\\n\",\n",
        "    \"    print(f\\\"✅ Detection complete! Processed {len(detections)} frames.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    tracker = ByteTrack(high_thresh=TRACKING_HIGH_THRESH, low_thresh=TRACKING_LOW_THRESH, max_time_lost=TRACKING_MAX_TIME_LOST)\\n\",\n",
        "    \"    all_tracklets = []\\n\",\n",
        "    \"    for frame_data in tqdm(detections, desc=\\\"Stage 2: Tracking Players\\\"):\\n\",\n",
        "    \"        tracks = tracker.update(frame_data['detections']['players'])\\n\",\n",
        "    \"        all_tracklets.append({\\\"frame_id\\\": frame_data['frame_id'], \\\"tracks\\\": tracks})\\n\",\n",
        "    \"    with open(tracklets_path, 'w') as f: json.dump(all_tracklets, f, indent=2)\\n\",\n",
        "    \"    print(f\\\"✅ Tracking complete! Processed {len(all_tracklets)} frames.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    reid = PlayerReID()\\n\",\n",
        "    \"    long_tracks = reid.process_tracklets(tracklets_path, video_path, long_tracks_path)\\n\",\n",
        "    \"    print(f\\\"✅ Re-ID & Team Classification complete! Identified {len(reid.global_players)} unique players.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    cap = cv2.VideoCapture(video_path)\\n\",\n",
        "    \"    video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\\n\",\n",
        "    \"    video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\\n\",\n",
        "    \"    fps = cap.get(cv2.CAP_PROP_FPS)\\n\",\n",
        "    \"    cap.release()\\n\",\n",
        "    \"\\n\",\n",
        "    \"    event_detector = AdvancedEventDetector(video_width, video_height, fps)\\n\",\n",
        "    \"    player_events = event_detector.detect_events(long_tracks_path, detections_path, events_path)\\n\",\n",
        "    \"    print(f\\\"✅ Advanced event detection complete! Found {len(player_events)} unique highlight events.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    assembler = VideoAssembler()\\n\",\n",
        "    \"    success = assembler.assemble_highlight_reel(video_path, events_path, highlight_path, TARGET_JERSEY_NUMBER, TOP_N_EVENTS)\\n\",\n",
        "    \"    if success:\\n\",\n",
        "    \"        print(f\\\"✅ Highlight reel saved to: {highlight_path}\\\")\\n\",\n",
        "    \"    else:\\n\",\n",
        "    \"        print(\\\"❌ Failed to create highlight reel\\\")\\n\",\n",
        "    \"else:\\n\",\n",
        "    \"    print(\\\"❌ No video path available. Please run the upload cell first.\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"run_pipeline\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"markdown\",\n",
        "   \"source\": [\n",
        "    \"## 📥 5. Download Results\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"download_markdown\"\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"from google.colab import files\\n\",\n",
        "    \"\\n\",\n",
        "    \"if 'success' in locals() and success and 'highlight_path' in locals() and os.path.exists(highlight_path):\\n\",\n",
        "    \"    files.download(highlight_path)\\n\",\n",
        "    \"    print(f\\\"✅ Downloaded: {os.path.basename(highlight_path)}\\\")\\n\",\n",
        "    \"else:\\n\",\n",
        "    \"    print(f\\\"❌ Could not download highlight reel. File not found or creation failed.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"if os.path.exists('/content/output/long_player_track.json'):\\n\",\n",
        "    \"    files.download('/content/output/long_player_track.json')\\n\",\n",
        "    \"    print(\\\"✅ Downloaded: long_player_track.json\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"if os.path.exists('/content/output/player_events.json'):\\n\",\n",
        "    \"    files.download('/content/output/player_events.json')\\n\",\n",
        "    \"    print(\\\"✅ Downloaded: player_events.json\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"\\\\n🎉 Pipeline complete! Check your browser's downloads folder.\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"download_results\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  },\n",
        "  {\n",
        "   \"cell_type\": \"code\",\n",
        "   \"source\": [\n",
        "    \"print(\\\"📊 PIPELINE SUMMARY\\\")\\n\",\n",
        "    \"print(\\\"=\\\" * 50)\\n\",\n",
        "    \"\\n\",\n",
        "    \"if 'video_path' in locals() and video_path and os.path.exists('/content/output/long_player_track.json') and os.path.exists('/content/output/player_events.json'):\\n\",\n",
        "    \"    with open('/content/output/long_player_track.json', 'r') as f:\\n\",\n",
        "    \"        long_tracks_summary = json.load(f)\\n\",\n",
        "    \"    with open('/content/output/player_events.json', 'r') as f:\\n\",\n",
        "    \"        player_events_summary = json.load(f)\\n\",\n",
        "    \"\\n\",\n",
        "    \"    print(f\\\"📹 Video processed: {os.path.basename(video_path)}\\\")\\n\",\n",
        "    \"    print(f\\\"🎯 Target player jersey: {TARGET_JERSEY_NUMBER}\\\")\\n\",\n",
        "    \"    print(f\\\"🖼️ Total frames processed: {len(long_tracks_summary)}\\\")\\n\",\n",
        "    \"    print(f\\\"✨ Total unique events detected: {len(player_events_summary)}\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"    if 'success' in locals() and success and 'highlight_path' in locals() and os.path.exists(highlight_path):\\n\",\n",
        "    \"        print(f\\\"⏱️ Highlight reel generated successfully for Top {TOP_N_EVENTS} events.\\\")\\n\",\n",
        "    \"        file_size = os.path.getsize(highlight_path) / (1024 * 1024)\\n\",\n",
        "    \"        print(f\\\"📁 Output file size: {file_size:.1f} MB\\\")\\n\",\n",
        "    \"    else:\\n\",\n",
        "    \"        print(\\\"⏱️ Highlight reel was not generated.\\\")\\n\",\n",
        "    \"else:\\n\",\n",
        "    \"    print(\\\"Could not generate summary. One or more output files are missing.\\\")\\n\",\n",
        "    \"\\n\",\n",
        "    \"print(\\\"=\\\" * 50)\\n\",\n",
        "    \"print(\\\"🎉 Pipeline finished!\\\")\"\n",
        "   ],\n",
        "   \"metadata\": {\n",
        "    \"id\": \"summary\"\n",
        "   },\n",
        "   \"execution_count\": null,\n",
        "   \"outputs\": []\n",
        "  }\n",
        " ]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMbs95bPHmae"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuppub2AHmaf"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWl7tVL8Hmaf"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Download highlight reel\n",
        "if 'success' in locals() and success and 'highlight_path' in locals() and os.path.exists(highlight_path):\n",
        "    files.download(highlight_path)\n",
        "    print(f\"✅ Downloaded: {os.path.basename(highlight_path)}\")\n",
        "else:\n",
        "    print(f\"❌ Could not download highlight reel. File not found or creation failed.\")\n",
        "\n",
        "# Download all JSON outputs\n",
        "json_files = [\n",
        "    '/content/output/detections.json',\n",
        "    '/content/output/tracklets.json', \n",
        "    '/content/output/long_player_track.json',\n",
        "    '/content/output/player_events.json'\n",
        "]\n",
        "\n",
        "for json_file in json_files:\n",
        "    if os.path.exists(json_file):\n",
        "        files.download(json_file)\n",
        "        print(f\"✅ Downloaded: {os.path.basename(json_file)}\")\n",
        "    else:\n",
        "        print(f\"❌ Not found: {os.path.basename(json_file)}\")\n",
        "\n",
        "print(\"\\n📥 Download complete! Check your browser's downloads folder.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os, json, cv2\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "os.makedirs('/content/output', exist_ok=True)\n",
        "\n",
        "detections_path = '/content/output/detections.json'\n",
        "tracklets_path = '/content/output/tracklets.json'\n",
        "long_tracks_path = '/content/output/long_player_track.json'\n",
        "events_path = '/content/output/player_events.json'\n",
        "highlight_path = f'/content/output/player_{TARGET_JERSEY_NUMBER}_highlights.mp4'\n",
        "\n",
        "outputs_required = [detections_path, tracklets_path, long_tracks_path, events_path]\n",
        "\n",
        "ran = False\n",
        "if 'video_path' in globals() and video_path:\n",
        "    if not all(os.path.exists(p) for p in outputs_required):\n",
        "        detector = SoccerObjectDetector(model_name=YOLO_MODEL_SIZE, conf_thresh=DETECTION_CONF_THRESHOLD, min_area=MIN_BBOX_AREA)\n",
        "        detections = detector.process_video(video_path, detections_path)\n",
        "        tracker = ByteTrack(high_thresh=TRACKING_HIGH_THRESH, low_thresh=TRACKING_LOW_THRESH, max_time_lost=TRACKING_MAX_TIME_LOST)\n",
        "        all_tracklets = []\n",
        "        for frame_data in tqdm(detections, desc='Stage 2: Tracking Players'):\n",
        "            tracks = tracker.update(frame_data['detections']['players'])\n",
        "            all_tracklets.append({'frame_id': frame_data['frame_id'], 'tracks': tracks})\n",
        "        with open(tracklets_path, 'w') as f: json.dump(all_tracklets, f, indent=2)\n",
        "        reid = PlayerReID()\n",
        "        reid.process_tracklets(tracklets_path, video_path, long_tracks_path)\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        vw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)); vh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)); fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        cap.release()\n",
        "        ed = AdvancedEventDetector(vw, vh, fps)\n",
        "        ed.detect_events(long_tracks_path, detections_path, events_path)\n",
        "        assembler = VideoAssembler()\n",
        "        success = assembler.assemble_highlight_reel(video_path, events_path, highlight_path, TARGET_JERSEY_NUMBER, TOP_N_EVENTS)\n",
        "        ran = True\n",
        "else:\n",
        "    print('❌ No video uploaded. Please run the upload cell first.')\n",
        "\n",
        "if 'success' in locals() and success and os.path.exists(highlight_path):\n",
        "    files.download(highlight_path)\n",
        "    print(f\"✅ Downloaded: {os.path.basename(highlight_path)}\")\n",
        "\n",
        "for json_file in outputs_required:\n",
        "    if os.path.exists(json_file):\n",
        "        files.download(json_file)\n",
        "        print(f\"✅ Downloaded: {os.path.basename(json_file)}\")\n",
        "\n",
        "print(\"\\n📥 Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOvFtiejHmaf"
      },
      "outputs": [],
      "source": [
        "print(\"📊 DETAILED PIPELINE SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if 'video_path' in locals() and video_path and os.path.exists('/content/output/long_player_track.json') and os.path.exists('/content/output/player_events.json'):\n",
        "    with open('/content/output/long_player_track.json', 'r') as f:\n",
        "        long_tracks_summary = json.load(f)\n",
        "    with open('/content/output/player_events.json', 'r') as f:\n",
        "        player_events_summary = json.load(f)\n",
        "\n",
        "    print(f\"📹 Video processed: {os.path.basename(video_path)}\")\n",
        "    print(f\"🎯 Target player jersey: {TARGET_JERSEY_NUMBER}\")\n",
        "    print(f\"🖼️ Total frames processed: {len(long_tracks_summary)}\")\n",
        "    print(f\"✨ Total unique events detected: {len(player_events_summary)}\")\n",
        "\n",
        "    # Player statistics\n",
        "    if 'reid' in globals() and reid.global_players:\n",
        "        print(f\"👥 Unique players identified: {len(reid.global_players)}\")\n",
        "        confirmed_jerseys = [p.get('confirmed_jersey') for p in reid.global_players.values() if p.get('confirmed_jersey')]\n",
        "        print(f\"🔢 Players with confirmed jersey numbers: {len(confirmed_jerseys)}\")\n",
        "        if confirmed_jerseys:\n",
        "            print(f\"🔢 Jersey numbers found: {sorted(confirmed_jerseys)}\")\n",
        "\n",
        "    # Event breakdown\n",
        "    event_types = {}\n",
        "    for event in player_events_summary:\n",
        "        event_type = event.get('event_type', 'unknown')\n",
        "        event_types[event_type] = event_types.get(event_type, 0) + 1\n",
        "    \n",
        "    print(f\"\\n📌 Events by type:\")\n",
        "    for event_type, count in event_types.items():\n",
        "        print(f\"   • {event_type}: {count}\")\n",
        "\n",
        "    # Target player events\n",
        "    target_player_id = None\n",
        "    if 'reid' in globals() and reid.global_players:\n",
        "        for pid, p_info in reid.global_players.items():\n",
        "            if p_info.get('confirmed_jersey') == TARGET_JERSEY_NUMBER:\n",
        "                target_player_id = pid; break\n",
        "\n",
        "    target_events = [e for e in player_events_summary if target_player_id and e.get('player_id') == target_player_id]\n",
        "    print(f\"\\n🎯 Events for player {TARGET_JERSEY_NUMBER}: {len(target_events)}\")\n",
        "    \n",
        "    if target_events:\n",
        "        target_event_types = {}\n",
        "        for event in target_events:\n",
        "            event_type = event.get('event_type', 'unknown')\n",
        "            target_event_types[event_type] = target_event_types.get(event_type, 0) + 1\n",
        "        for event_type, count in target_event_types.items():\n",
        "            print(f\"   • {event_type}: {count}\")\n",
        "\n",
        "    # Highlight reel status\n",
        "    if 'success' in locals() and success and 'highlight_path' in locals() and os.path.exists(highlight_path):\n",
        "        print(f\"\\n⏱️ Highlight reel generated successfully!\")\n",
        "        print(f\"📁 Output file: {os.path.basename(highlight_path)}\")\n",
        "        file_size = os.path.getsize(highlight_path) / (1024 * 1024)\n",
        "        print(f\"📊 File size: {file_size:.1f} MB\")\n",
        "        print(f\"🏆 Top {TOP_N_EVENTS} events included\")\n",
        "    else:\n",
        "        print(f\"\\n⏱️ Highlight reel was not generated.\")\n",
        "        if target_events:\n",
        "            print(f\"💡 Tip: If the player was detected, try increasing TOP_N_EVENTS or lowering thresholds.\")\n",
        "else:\n",
        "    print(\"❌ Could not generate summary. One or more output files are missing.\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"🎉 Pipeline finished!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
